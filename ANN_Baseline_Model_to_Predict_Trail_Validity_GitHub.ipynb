{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedfadul/ANN-Baseline-Model-to-Predict-Trail-Validity/blob/main/ANN_Baseline_Model_to_Predict_Trail_Validity_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwSw8INOSUty"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "pip install tensorflow-addons\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow_addons import losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoEVS6pnS8aP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQZYNEqJZsB-",
        "outputId": "97477386-1994-452a-cb05-9bfa6c853629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install -q seaborn\n",
        "\n",
        "# Use some functions from tensorflow_docs\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYEvwS2_ZmUu"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8cTfgs4cFAu",
        "outputId": "9bde25c3-e122-42e3-93da-84c918aca955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTlEKxmZcKV7"
      },
      "outputs": [],
      "source": [
        "all_dataset = pd.read_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dJumq95Uqrn"
      },
      "outputs": [],
      "source": [
        "dataset = all_dataset.sample(frac=0.80,random_state=0)\n",
        "test_dataset = all_dataset.drop(dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Gvv4CSU2HD"
      },
      "outputs": [],
      "source": [
        "dataset['sboxes'] = ((dataset['sboxes']/(dataset['round']*8)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dada87UmQP9F"
      },
      "outputs": [],
      "source": [
        "test_dataset['sboxes'] = ((test_dataset['sboxes']/(test_dataset['round']*8)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIOVq3G3w9dx"
      },
      "outputs": [],
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1 = dataset.validity.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_0 = dataset[dataset['validity'] == 0]\n",
        "df_class_1 = dataset[dataset['validity'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtNzZyl-yWrE"
      },
      "outputs": [],
      "source": [
        "df_class_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FggsXsDqycjM"
      },
      "outputs": [],
      "source": [
        "df_class_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_b6MO7yy9U9"
      },
      "outputs": [],
      "source": [
        "#UnderSampling\n",
        "# Undersample 0-class and concat the DataFrames of both class\n",
        "df_class_0_under = df_class_0.sample(count_class_1)\n",
        "train_dataset = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "\n",
        "print('Random under-sampling:')\n",
        "print(train_dataset.validity.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IWtvp82j9PH"
      },
      "outputs": [],
      "source": [
        "train_labels = train_dataset.pop(\"validity\")\n",
        "test_labels = test_dataset.pop(\"validity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1za9mLhXIA1G"
      },
      "outputs": [],
      "source": [
        "train_dataset['round'] = (train_dataset['round'])/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chFFNqf7QvTx"
      },
      "outputs": [],
      "source": [
        "test_dataset['round'] = (test_dataset['round'])/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YbfL-U9blpi"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        y_pred = ops.convert_to_tensor_v2(y_pred)\n",
        "        y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6vwwJyD9RZ4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix , classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2k0D58J9fAf"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "\n",
        "reg_param=0.001\n",
        "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation='relu' , input_shape=[50]),\n",
        "        layers.Dense(512, activation='relu'),    \n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),     \n",
        "      layers.Dense(1,activation='sigmoid' )\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor='accuracy', patience=10,restore_best_weights=True)\n",
        "    if weights == -1:\n",
        "        model.fit(X_train, y_train, epochs=50, callbacks=[early_stop])\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "    \n",
        "    print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "    y_preds = model.predict(X_test)\n",
        "    y_preds = np.round(y_preds)\n",
        "    \n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb-Xu13e9pNf"
      },
      "outputs": [],
      "source": [
        "model = ANN(train_dataset, train_labels, test_dataset, test_labels, tf.keras.losses.BinaryCrossentropy(), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idyH1a2VTkZG"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/Truncated path validity/truncated_validity_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qOIMzI8RU_OVMpTZtLpymE7NDhWk7-NN",
      "authorship_tag": "ABX9TyP9prQ/ZPXxxP5cSKtqt0S5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}